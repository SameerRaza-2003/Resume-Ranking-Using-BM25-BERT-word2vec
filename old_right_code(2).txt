import streamlit as st
import extraction
import applyprocessing as ap
import bma
import querypre
import word2vec as w2v
from sklearn.metrics.pairwise import cosine_similarity
import openai
import os
import google.generativeai as genai
import requests
import time
# Hardcoding your Gemini API key
#genai.configure(api_key="AIzaSyAlNq-uhihqv0FSpgD7Jdo5sDIX0xeWtGQ")


import time
GROQ_API_KEY = "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"
def explain_with_groq(algorithm_name, job_description, resume_text, score):
    # Truncate inputs to reduce token usage
    resume_text = resume_text[:3000]
    job_description = job_description[:1000]

    prompt = f"""
    Job Description:
    {job_description}

    Resume:
    {resume_text}

    Similarity Score: {score:.4f}

    In exactly 4 lines, explain in a single paragraph why this resume is relevant or not using {algorithm_name}. Avoid bullet points. Be clear and concise. Prefix with either 'Good Fit:' or 'Bad Fit:'.
    """

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "llama3-70b-8192",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    }

    # Retry logic
    for attempt in range(3):  # Try up to 3 times
        try:
            response = requests.post(url, headers=headers, json=payload)
            result = response.json()

            if 'error' in result:
                error_msg = result['error']['message']
                if "rate limit" in error_msg.lower() or "please try again" in error_msg.lower():
                    wait_time = 8 + attempt * 2
                    time.sleep(wait_time)
                    continue  # retry
                elif "request too large" in error_msg.lower():
                    return f"‚ö†Ô∏è Resume too long. Skipped to avoid Groq token limit."
                else:
                    return f"‚ö†Ô∏è Groq API error: {error_msg}"

            # Pause to avoid hitting TPM limits
            time.sleep(1.5)

            return result['choices'][0]['message']['content']

        except Exception as e:
            time.sleep(2)
            continue  # try again

    return "‚ùå Failed after multiple Groq attempts."

def batch_groq_fit_evaluation(algorithm_name, job_description, resume_score_data):
    good_fits = []
    bad_fits = []

    for file_name, score, resume_text in resume_score_data:
        with st.spinner(f"Evaluating: {file_name}"):
            explanation = explain_with_groq(algorithm_name, job_description, resume_text, score)

        if explanation.strip().lower().startswith("good fit") or "**Good Fit**" in explanation:
            good_fits.append((file_name, score, explanation))
        else:
            bad_fits.append((file_name, score, explanation))

    return good_fits, bad_fits



st.set_page_config(
    page_title="Resume Ranking-Using BM25",
    page_icon="üìÑ",
    layout="centered"
)

st.title("Resume Ranking-Using BM25")
st.subheader("Upload your resumes to rank them using BM25, etc.")
st.markdown("Start uploading resumes and a job description below:")

uploaded_files = st.file_uploader("Upload Resume", type=["pdf", "docx", "txt"], accept_multiple_files=True)
if uploaded_files:
    st.success(f"{len(uploaded_files)} files uploaded")
    
    df1 = extraction.extract_text(uploaded_files)
    
    st.dataframe(df1[['File Name', 'Resume Text']])
    
    preprocesseddf = ap.preprocess_resumes(df1)
    for index, row in preprocesseddf.iterrows():
        with st.expander(f"Resume {row['File Name']}"):
            st.write(row['Processed Text'])

            # ‚úÖ GEMINI RAG EXPLANATION SECTION ‚Äî INSIDE THIS BLOCK
        #GROQ_API_KEY = "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"

    # selected_resume = st.selectbox("Select a Resume", df1['File Name'].tolist())
    # job_description = st.text_area("Paste the Job Description", key="job_description_1")

    # if st.button("Generate Explanation with Mixtral"):
    #     selected_text = preprocesseddf[preprocesseddf['File Name'] == selected_resume]['Processed Text'].values[0]

    #     with st.spinner("Calling Mixtral via Groq..."):
    #         explanation = explain_with_groq("Mixtral", job_description, selected_text, score=0.0)
    #         st.success("Explanation Generated")
    #         st.markdown(explanation)
else:
    st.info("You can upload multiple PDF, DOC files.")

job_description = st.text_area(
    "Paste the Job Description Here",
    placeholder="Example: We're looking for a Python developer with experience in NLP and machine learning..."
)

st.markdown("---")

algorithms = st.multiselect(
    "Select Ranking Algorithm(s)",
    ["TF-IDF", "BM25", "Word2Vec", "BERT"],
    default=["TF-IDF"]
)

with st.expander("‚ÑπÔ∏è What do these algorithms mean?"):
    st.markdown(""" 
    - **TF-IDF**: Calculates word importance by frequency.
    - **BM25**: A probabilistic ranking method.
    - **Word2Vec**: Uses word embeddings for context.
    - **BERT**: Deep contextualized transformer model.
    """)

if "ranking_done" not in st.session_state:
    st.session_state.ranking_done = False
if st.button("üîé Rank Resumes"):
    if not uploaded_files or not job_description or not algorithms:
        st.warning("Please upload files, enter a job description, and select at least one algorithm.")
    else:
        st.session_state.ranking_done = True  # ‚úÖ Mark ranking as completed

        processed_text_list = preprocesseddf['Processed Text'].tolist()
        job_query = querypre.preprocess(job_description)

        for algo in algorithms:
            if algo == "BM25":
                st.subheader("üìä BM25 Ranking")
                bm25_result = bma.applybm25(processed_text_list, job_query)
                st.session_state.bm25_ranked = sorted(zip(bm25_result, df1['File Name']), reverse=True)
                st.write("### üìà Ranked Resumes (BM25)")
                for i, (score, file_name) in enumerate(st.session_state.bm25_ranked, start=1):
                    st.markdown(f"**{i}. {file_name}** ‚Äî Similarity Score: `{score:.4f}`")

            if algo == "Word2Vec":
                st.subheader("Word2Vec Ranking")
                model = w2v.train_word2vec([tokens for tokens in processed_text_list])
                resume_vectors = [w2v.get_average_vector(tokens, model) for tokens in processed_text_list]
                job_vector = w2v.get_average_vector(job_query, model)
                similarities = [cosine_similarity([resume_vector], [job_vector])[0][0] for resume_vector in resume_vectors]
                st.session_state.word2vec_ranked = sorted(zip(similarities, df1['File Name']), reverse=True)
                st.write("### üìà Ranked Resumes (Word2Vec)")
                for i, (score, file_name) in enumerate(st.session_state.word2vec_ranked, start=1):
                    st.markdown(f"**{i}. {file_name}** ‚Äî Similarity Score: `{score:.4f}`")

# ‚úÖ Groq Evaluation ‚Äî now OUTSIDE the button so it persists after reruns
if st.session_state.get("ranking_done", False):
    for algo in algorithms:
        algo_key = algo.lower().replace("-", "").replace(" ", "")
        rank_key = f"{algo_key}_ranked"

        if rank_key in st.session_state:
            st.markdown(f"---\n## ü§ñ Groq Evaluation for {algo}")
            resume_score_data = [
                (file_name, score, preprocesseddf[preprocesseddf['File Name'] == file_name]['Processed Text'].values[0])
                for score, file_name in st.session_state[rank_key]
            ]

            if st.button(f"Use Groq to Classify & Explain ({algo})"):
                good_fits, bad_fits = batch_groq_fit_evaluation(algo, job_description, resume_score_data)

                st.subheader("‚úÖ Good Fit Resumes")
                for file_name, score, explanation in good_fits:
                    st.markdown(f"**{file_name}** ‚Äî Score: `{score:.4f}`")
                    st.markdown(explanation)
                    st.markdown("---")

                st.subheader("‚ùå Bad Fit Resumes")
                for file_name, score, explanation in bad_fits:
                    st.markdown(f"**{file_name}** ‚Äî Score: `{score:.4f}`")
                    st.markdown(explanation)
                    st.markdown("---")
